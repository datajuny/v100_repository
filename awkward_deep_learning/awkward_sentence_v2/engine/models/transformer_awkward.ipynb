{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting awkward.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile awkward.py\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class awkwardClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 ntoken, # 단어수\n",
    "                 ntoken2,\n",
    "                 ninp,   # 임베딩 차원\n",
    "                 n_classes,\n",
    "                 nhead, \n",
    "                 nhid, \n",
    "                 nlayers,\n",
    "                 use_batch_norm=False,\n",
    "                 dropout=0.5):\n",
    "\n",
    "        super(awkwardClassifier, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        \n",
    "        self.ninp = ninp\n",
    "        self.encoder = nn.Embedding(ntoken, ninp, padding_idx=1)\n",
    "        self.encoder2 = nn.Embedding(ntoken2, ninp, padding_idx=1)\n",
    "        \n",
    "        ## 첫번째 문장\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        #self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        ## 두번째 문장\n",
    "        self.pos_encoder2 = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers2 = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder2 = TransformerEncoder(encoder_layers2, nlayers)\n",
    "        #self.decoder2 = nn.Linear(ninp, ntoken)\n",
    "        \n",
    "        ## 문장간 유사도\n",
    "        #self.con_li = nn.Linear(ninp, n_classes)\n",
    "        self.con_li = nn.Linear(64, n_classes) # 시퀀스 길이 x 클래스 갯수\n",
    "        self.activation = nn.LogSoftmax(dim=-1)\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        \n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.encoder2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.con_li.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "        #self.decoder.bias.data.zero_()\n",
    "        #self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        #self.decoder2.bias.data.zero_()\n",
    "        #self.decoder2.weight.data.uniform_(-initrange, initrange)\n",
    "        #self.result.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "\n",
    "    def forward(self, src, src2):\n",
    "        \n",
    "        ## 첫번째 문장\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        #output = self.decoder(output)\n",
    "        \n",
    "        ## 두번째 문장\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src2):\n",
    "            device = src2.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src2)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src2 = self.encoder2(src2) * math.sqrt(self.ninp)\n",
    "        src2 = self.pos_encoder2(src2)\n",
    "        output2 = self.transformer_encoder2(src2, self.src_mask)\n",
    "        # output2 = self.decoder2(output2)\n",
    "\n",
    "        #final_outs = torch.cat([output, output2], dim = 2)\n",
    "        ## <1차 성공>\n",
    "        #  final_outs = torch.add(output, output2)\n",
    "        #  output = self.con_li(final_outs)\n",
    "\n",
    "        # y = self.activation(output[:, -1])\n",
    "        ## </1차 성공>\n",
    "    \n",
    "        ## <2차 시도>\n",
    "        #final_outs = torch.exp(-torch.sum(torch.abs(output - output2), dim=2)) # 성공 (7, 64) -> 모두 0 아니면 1로\n",
    "        final_outs = -torch.sum(torch.abs(output - output2), dim=2) # 성공 (7, 64) -> torch.exp적용시 정확도가 떨어지는 현상 보여 제외함.\n",
    "        output = self.con_li(final_outs)\n",
    "        y = self.activation(output)\n",
    "        \n",
    "        return y\n",
    "        #return torch.argmax(y, dim=1)\n",
    "\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_x -> (9, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Backup</h1>\n",
    "\n",
    "200614_v1 : 한문장, 라벨 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile awkward.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class awkwardClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        word_vec_size,\n",
    "        n_classes,\n",
    "        use_batch_norm=False,\n",
    "        dropout_p=.5\n",
    "    ):\n",
    "        \n",
    "        self.input_size = input_size  # vocabulary size\n",
    "        self.word_vec_size = word_vec_size\n",
    "        self.n_classes = n_classes\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(input_size, word_vec_size)\n",
    "        self.generator  = nn.Linear(word_vec_size, n_classes)\n",
    "        self.activation = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # |x| = (batch_size, length, word_vec_size)\n",
    "        x = self.emb(x)\n",
    "        \n",
    "        #|gen_x| = (batch_size, length, n_classes)\n",
    "        #print(gen_x.shape) [9, 64, 3]\n",
    "        gen_x = self.generator(x)\n",
    "\n",
    "        # |y| = (batch_size, n_classes)\n",
    "        y = self.activation(gen_x[:, -1])\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Backup</h1>\n",
    "\n",
    "200614_v2: 두문장, 라벨 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile awkward.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class awkwardClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        word_vec_size,\n",
    "        n_classes,\n",
    "        use_batch_norm=False,\n",
    "        dropout_p=.5\n",
    "    ):\n",
    "        \n",
    "        self.input_size = input_size  # vocabulary size\n",
    "        self.word_vec_size = word_vec_size\n",
    "        self.n_classes = n_classes\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(input_size, word_vec_size)\n",
    "        \n",
    "        self.generator  = nn.Linear(word_vec_size, n_classes)\n",
    "        self.generator_x2  = nn.Linear(word_vec_size, n_classes)\n",
    "        \n",
    "        self.concat  = nn.Linear(n_classes * 2, n_classes)\n",
    "        \n",
    "        self.activation = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, x2):\n",
    "        \n",
    "        # |x| = (batch_size, length, word_vec_size)\n",
    "        x = self.emb(x)\n",
    "        x2 = self.emb(x2)\n",
    "        \n",
    "        #|gen_x| = (batch_size, length, n_classes)\n",
    "        #print(gen_x.shape) [9, 64, 3]\n",
    "        gen_x = self.generator(x)\n",
    "        gen_x2 = self.generator_x2(x)\n",
    "        \n",
    "        gen_outs = torch.cat((gen_x, gen_x2), dim=-1)\n",
    "        print(\"gen_outs\", gen_outs.shape)\n",
    "        \n",
    "        y_hat = self.concat(gen_outs)\n",
    "        \n",
    "        print(\"y_hat\", y_hat.shape)\n",
    "        # |y| = (batch_size, n_classes)\n",
    "        y = self.activation(y_hat[:, -1])\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Backup</h1>\n",
    "\n",
    "200614_v3: 두문장, 라벨 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile awkward.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class awkwardClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        word_vec_size,\n",
    "        n_classes,\n",
    "        use_batch_norm=False,\n",
    "        dropout_p=.5\n",
    "    ):\n",
    "        \n",
    "        self.input_size = input_size  # vocabulary size\n",
    "        self.word_vec_size = word_vec_size\n",
    "        self.n_classes = n_classes\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(input_size, word_vec_size)\n",
    "        \n",
    "        self.generator  = nn.Linear(word_vec_size, n_classes)\n",
    "        self.generator_x2  = nn.Linear(word_vec_size, n_classes)\n",
    "        \n",
    "        self.concat  = nn.Linear(1, n_classes)\n",
    "        \n",
    "        self.activation = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, x2):\n",
    "        \n",
    "        # |x| = (batch_size, length, word_vec_size)\n",
    "        x = self.emb(x)\n",
    "        x2 = self.emb(x2)\n",
    "        \n",
    "        #|gen_x| = (batch_size, length, n_classes)\n",
    "        #print(gen_x.shape) [9, 64, 3]\n",
    "        gen_x = self.generator(x)\n",
    "        gen_x2 = self.generator_x2(x)\n",
    "        \n",
    "        gen_outs = torch.exp(-torch.sum(torch.abs(gen_x - gen_x2), dim=2, keepdim=True))\n",
    "        \n",
    "        y_hat = self.concat(gen_outs)\n",
    "        \n",
    "        # |y| = (batch_size, n_classes)\n",
    "        y = self.activation(y_hat[:, -1])\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Backup</h1>\n",
    "\n",
    "200614_v4: 두문장, 라벨 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile awkward.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class awkwardClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        word_vec_size,\n",
    "        n_classes,\n",
    "        use_batch_norm=False,\n",
    "        dropout_p=.5\n",
    "    ):\n",
    "        \n",
    "        self.input_size = input_size  # vocabulary size\n",
    "        self.word_vec_size = word_vec_size\n",
    "        self.n_classes = n_classes\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(input_size, word_vec_size)\n",
    "        \n",
    "        self.generator  = nn.Linear(word_vec_size, n_classes)\n",
    "        self.generator_x2  = nn.Linear(word_vec_size, n_classes)\n",
    "        \n",
    "        self.concat  = nn.Linear(1, n_classes)\n",
    "        \n",
    "        self.activation = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, x2):\n",
    "        \n",
    "        # |x| = (batch_size, length, word_vec_size)\n",
    "        x = self.emb(x)\n",
    "        x2 = self.emb(x2)\n",
    "        \n",
    "        #|gen_x| = (batch_size, length, n_classes)\n",
    "        #print(gen_x.shape) [9, 64, 3]\n",
    "        gen_x = self.generator(x)\n",
    "        gen_x2 = self.generator_x2(x)\n",
    "        \n",
    "        gen_outs = torch.exp(-torch.sum(torch.abs(gen_x - gen_x2), dim=2, keepdim=True))\n",
    "        \n",
    "        y_hat = self.concat(gen_outs)\n",
    "        \n",
    "        # |y| = (batch_size, n_classes)\n",
    "        y = self.activation(y_hat[:, -1])\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Backup</h1>\n",
    "\n",
    "200614_v5: 트랜스포머, 한문장, 라벨 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile awkward.py\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class awkwardClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 ntoken, \n",
    "                 ninp,  \n",
    "                 n_classes,\n",
    "                 nhead, \n",
    "                 nhid, \n",
    "                 nlayers,\n",
    "                 use_batch_norm=False,\n",
    "                 dropout=0.5):\n",
    "\n",
    "        super(awkwardClassifier, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        \n",
    "        ## 첫번째 문장\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        \n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    def forward(self, src, src2):\n",
    "        \n",
    "        ## 첫번째 문장\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        \n",
    "        return output[:,-1]\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Backup</h1>\n",
    "\n",
    "200614_v6: 10건 테스트 정상 학습, 트랜스포머, 두문장, 라벨 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile awkward.py\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class awkwardClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 ntoken, # 단어수\n",
    "                 ninp,   # 임베딩 차원\n",
    "                 n_classes,\n",
    "                 nhead, \n",
    "                 nhid, \n",
    "                 nlayers,\n",
    "                 use_batch_norm=False,\n",
    "                 dropout=0.5):\n",
    "\n",
    "        super(awkwardClassifier, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        \n",
    "        ## 첫번째 문장        \n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "        \n",
    "        ## 두번째 문장        \n",
    "        self.pos_encoder2 = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers2 = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder2 = TransformerEncoder(encoder_layers2, nlayers)\n",
    "        self.encoder2 = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp2 = ninp\n",
    "        self.decoder2 = nn.Linear(ninp, ntoken)\n",
    "        \n",
    "        ## 문장간 유사도\n",
    "        self.con_li = nn.Linear(ntoken, n_classes)\n",
    "        self.activation = nn.LogSoftmax(dim=-1)\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        \n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "#         self.encoder2.weight.data.uniform_(-initrange, initrange)\n",
    "#         self.decoder2.bias.data.zero_()\n",
    "#         self.decoder2.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "#         self.result.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "\n",
    "    def forward(self, src, src2):\n",
    "        \n",
    "        ## 첫번째 문장\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        \n",
    "        ## 두번째 문장\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src2):\n",
    "            device = src2.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src2)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src2 = self.encoder2(src2) * math.sqrt(self.ninp2)\n",
    "        src2 = self.pos_encoder2(src2)\n",
    "        output2 = self.transformer_encoder2(src2, self.src_mask)\n",
    "        output2 = self.decoder2(output2)\n",
    "        \n",
    "        ## 두 문장간 유사도\n",
    "        #final_outs = torch.exp(-torch.sum(torch.abs(output - output2), dim=2, keepdim=True))\n",
    "        #final_outs = result(torch.exp(-torch.sum(torch.abs(output - output2), dim=2, keepdim=True)))\n",
    "        \n",
    "        print(\"output\",output.shape)\n",
    "        print(\"output2\",output2.shape)\n",
    "        \n",
    "        final_outs = torch.add(output, output2)\n",
    "        output = self.con_li(final_outs)\n",
    "\n",
    "        y = self.activation(output[:, -1])\n",
    "        return y\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext import data\n",
    "from konlpy.tag import Okt \n",
    "import torch\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "valid_ratio=0.1\n",
    "use_eos = True\n",
    "batch_size = 3\n",
    "device = torch.cuda.is_available()\n",
    "shuffle = True\n",
    "max_vocab = 9999999\n",
    "min_freq = 1\n",
    "\n",
    "# Define field of the input file.\n",
    "# The input file consists of two fields.\n",
    "text1 = data.Field(tokenize=okt.morphs,\n",
    "                   use_vocab = True,\n",
    "                   batch_first = True,\n",
    "                   include_lengths = False,\n",
    "                   eos_token='<EOS>' if use_eos else None,\n",
    "                   pad_first=True)\n",
    "\n",
    "text2 = data.Field(tokenize=okt.morphs,\n",
    "                   use_vocab = True,\n",
    "                   batch_first = True,\n",
    "                   include_lengths = False,\n",
    "                   eos_token='<EOS>' if use_eos else None,\n",
    "                   pad_first=True)\n",
    "\n",
    "# sequential : If False,no tokenization is applied\n",
    "label = data.Field(sequential = False,\n",
    "                   use_vocab = True,\n",
    "                   init_token=None,\n",
    "                   unk_token = None)\n",
    "\n",
    "# Those defined two columns will be delimited by TAB.\n",
    "# Thus, we use TabularDataset to load two columns in the input file.\n",
    "# We would have two separate input file: train_fn, valid_fn\n",
    "# Files consist of two columns: label field and text field.\n",
    "train, valid = data.TabularDataset(\n",
    "    path=\"/home/work/data/awkward_v2/data/albert_pretrain/sen_sen_label_v1_test.csv\",\n",
    "    format='tsv', \n",
    "    fields=[\n",
    "        ('text1', text1),\n",
    "        ('text2', text2),\n",
    "        ('label', label),\n",
    "    ],\n",
    ").split(split_ratio=(1 - valid_ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those loaded dataset would be feeded into each iterator:\n",
    "# train iterator and valid iterator.\n",
    "# We sort input sentences by length, to group similar lengths.\n",
    "train_loader, valid_loader = data.BucketIterator.splits(\n",
    "    (train, valid),\n",
    "    batch_size=batch_size,\n",
    "    device='cuda:%d' % device if device >= 0 else 'cpu',\n",
    "    shuffle=shuffle,\n",
    "    sort_key=lambda x: len(x.text1),\n",
    "    sort_within_batch=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At last, we make a vocabulary for label and text field.\n",
    "# It is making mapping table between words and indice.\n",
    "label.build_vocab(train)\n",
    "text1.build_vocab(train, max_size=max_vocab, min_freq=min_freq)\n",
    "text2.build_vocab(train, max_size=max_vocab, min_freq=min_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이가 다르다.\n",
    "for x, y in train_loader:\n",
    "    print(x[0].shape)\n",
    "    print(x[0])\n",
    "    \n",
    "    #print(x[1].shape)\n",
    "    #print(x[1])\n",
    "    \n",
    "    #print(x[2].shape)\n",
    "    print(\"구분\")\n",
    "    #padding_value (float, optional) – values for padded elements. // total_length\n",
    "    \n",
    "    packed = pack_padded_sequence(x[0], total_length = [32], batch_first=True, enforce_sorted=False)\n",
    "    print(packed)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Pad instances with 0s till max length sequence ##\n",
    "##--------------------------------------------------------##\n",
    "# get the length of each seq in your batch\n",
    "seq_lengths = LongTensor(list(map(len, vectorized_seqs)))\n",
    "# seq_lengths => [ 8, 4,  6]\n",
    "# batch_sum_seq_len: 8 + 4 + 6 = 18\n",
    "# max_seq_len: 8\n",
    "\n",
    "seq_tensor = Variable(torch.zeros((len(vectorized_seqs), seq_lengths.max()))).long()\n",
    "# seq_tensor => [[0 0 0 0 0 0 0 0]\n",
    "#                [0 0 0 0 0 0 0 0]\n",
    "#                [0 0 0 0 0 0 0 0]]\n",
    "\n",
    "for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "    seq_tensor[idx, :seqlen] = LongTensor(seq)\n",
    "# seq_tensor => [[ 6  9  8  4  1 11 12 10]          # long_str\n",
    "#                [12  5  8 14  0  0  0  0]          # tiny\n",
    "#                [ 7  3  2  5 13  7  0  0]]         # medium\n",
    "# seq_tensor.shape : (batch_size X max_seq_len) = (3 X 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 32\n",
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_seqs = [[6, 9, 8, 4, 1, 11, 12, 10],\n",
    "                   [12, 5, 8, 14],\n",
    "                   [7, 3, 2, 5, 13, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import LongTensor\n",
    "from torch.autograd import Variable\n",
    "\n",
    "max_length= 32\n",
    "\n",
    "# 길이가 다르다.\n",
    "for x, y in train_loader:\n",
    "\n",
    "    vectorized_seqs = x[0]\n",
    "    #print(x[1])\n",
    "    #print(x[2])\n",
    "    \n",
    "\n",
    "    #seq_lengths = LongTensor(list(map(len, vectorized_seqs)))\n",
    "    #seq_tensor = Variable(torch.zeros(batch_size, max_length)).long()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, 23, 84, 43,  5, 92,  7, 44,  6, 16,  4, 71, 94, 50, 48,  3, 30, 73,\n",
       "         34, 10, 67,  9, 18, 19, 95, 80, 22, 35, 45, 89, 76,  9, 15,  4, 12, 20,\n",
       "         88, 77, 97, 42, 78, 46, 82,  5, 31, 98, 56, 47, 61,  9,  6, 58, 99, 15,\n",
       "          4, 12, 20, 90, 19, 96, 52, 79, 57,  3,  2],\n",
       "        [ 8, 23, 84, 43,  5, 92,  7, 44,  6, 16,  4, 71, 94, 50, 48,  3, 30, 73,\n",
       "         34, 10, 67,  9, 18, 19, 95, 80, 22, 35, 45, 89, 76,  9, 15,  4, 12, 20,\n",
       "         88, 77, 97, 42, 78, 46, 82,  5, 31, 98, 56, 47, 61,  9,  6, 58, 99, 15,\n",
       "          4, 12, 20, 90, 19, 96, 52, 79, 57,  3,  2],\n",
       "        [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         70, 13, 60, 17, 87, 13, 16,  4, 28, 29,  7, 14, 21, 49, 18, 54,  8,  6,\n",
       "         72,  6, 81, 25, 11, 27, 17, 59, 51, 33, 91, 66, 65, 41, 36, 85,  7, 14,\n",
       "         21, 63, 74,  5, 32, 75, 69, 24, 93,  3,  2]], device='cuda:1')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_seqs = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths = LongTensor(list(map(len, vectorized_seqs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_tensor = Variable(torch.zeros(len(seq_lengths), max_length)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([65, 65, 65])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "    \n",
    "    #print(seq)\n",
    "    #print(seqlen)\n",
    "    \n",
    "    seq_tensor[idx, :seqlen]\n",
    "\n",
    "    print(seq_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_tensor = Variable(torch.zeros(batch_size, max_length)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### seq 길이 통일해주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(\n",
    "        [[0, 0, 0, 0, 5, 0, 6, 0, 4, 0, 3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0,\n",
    "         0, 0, 4, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
    "         0, 3, 0, 0, 6, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 6, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 2],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
    "         0, 3, 0, 0, 6, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 6, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 2],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 2],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 2],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor(\n",
    "        [[0, 0, 0, 0, 5, 0, 6, 0, 4, 0, 3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0,\n",
    "         0, 0, 4, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
    "         0, 3, 0, 0, 6, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 6, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 2],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
    "         0, 3, 0, 0, 6, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 6, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 2],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 2],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 2],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input : tensor(batch x maxinum_length) / seq_length\n",
    "# 1. 길때, 작을때 분기\n",
    "# 1-1\n",
    "# 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxinum_length = 84\n",
    "pad = 1\n",
    "batchsize = 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 64])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if a.size(1) >= maxinum_length:\n",
    "    a = a[:, :engine.config.max_length]\n",
    "    #x2 = x2[:, :engine.config.max_length]\n",
    "\n",
    "else:\n",
    "    pad_num = maxinum_length - a.size(1)\n",
    "    pad = torch.ones(batchsize, pad_num)\n",
    "    output = torch.cat([pad.long(), a], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_maxseq_to_batch(batch, max_length, device=-1):\n",
    "    \n",
    "    if batch.size(1) >= max_length:\n",
    "        batch = batch[:, :max_length]\n",
    "        \n",
    "    else:\n",
    "        pad_num = max_length - batch.size(1)\n",
    "        pad = torch.ones(batch.size(0), pad_num, device=device) # pad 값이 vocab index 1이라는 가정.\n",
    "        batch = torch.cat([pad.long(), batch], dim=-1)\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 5, 0, 6, 0,\n",
       "         4, 0, 3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 3, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 2],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 6, 0, 0, 0,\n",
       "         0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0,\n",
       "         0, 5, 0, 0, 0, 0, 0, 2],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 6, 0, 0, 0,\n",
       "         0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0,\n",
       "         0, 5, 0, 0, 0, 0, 0, 2],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5,\n",
       "         0, 0, 0, 0, 0, 0, 0, 2],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 3, 0, 0, 0, 0, 2],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 2],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 2]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "pad_to_maxseq_to_batch(a, 128, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 84])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 64])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 20])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         5, 0, 6, 0, 4, 0, 3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 4, 0,\n",
       "         0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0,\n",
       "         6, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         6, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 2],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0,\n",
       "         6, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         6, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 2],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 2],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 2],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([pad.long(), a], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'minus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-52b4f6623481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'minus'"
     ]
    }
   ],
   "source": [
    "torch.minus(a - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.5 on Python 3.6 (CUDA 10.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
